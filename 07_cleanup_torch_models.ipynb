{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d5bcaa-3292-44f9-ab96-04db5f58faeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01476047-0e63-40c1-ac8f-3efac512b4dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "\n",
    "from crescendo.analysis import Ensemble as CrescendoEnsemble\n",
    "from crescendo.analysis import HPTunedSet as CrescendoHPTunedSet\n",
    "from multimodal_molecules.core import _torch_models_from_Crescendo, Ensemble, scaler_from_estimator, save_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71841b42-eee1-42ba-8e22-a2fbef38c041",
   "metadata": {},
   "source": [
    "# Create torch model ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d335f7f-1557-4a53-b615-4d193bf2c5a7",
   "metadata": {},
   "source": [
    "Here we abstract away most external dependencies and create standalone models for people to use. We do this for every combination that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc2f431-d535-45c4-b3b0-6bb59e16aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in [\"C\", \"N\", \"O\", \"CN\", \"CO\", \"NO\", \"CNO\"]:\n",
    "    xanes_dir = \"_\".join([f\"{e}-XANES\" for e in element])\n",
    "    element_dir = \"-\".join([e for e in element])\n",
    "    print(xanes_dir, element_dir)\n",
    "    ensemble = CrescendoEnsemble.from_root(\n",
    "        f\"data/23-05-05-ensembles/{element_dir}\",\n",
    "        data_dir=f\"data/23-04-26-ml-data/{xanes_dir}\"\n",
    "    )\n",
    "    root = Path(f\"data/23-12-06_torch_models/{element_dir}\")\n",
    "    _torch_models_from_Crescendo(root, ensemble)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5162a7dc-0068-4b3a-b5bf-6c216ef7e863",
   "metadata": {},
   "source": [
    "Do the same thing for the cutoff-8 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d3358-44b7-49a6-80e9-117d824c04a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in [\"C\", \"N\", \"O\", \"CNO\"]:\n",
    "    xanes_dir = \"_\".join([f\"{e}-XANES\" for e in element])\n",
    "    element_dir = \"-\".join([e for e in element])\n",
    "    print(xanes_dir, element_dir)\n",
    "    ensemble = CrescendoEnsemble.from_root(\n",
    "        f\"data/23-05-13-ensembles-CUTOFF8/{element_dir}\",\n",
    "        data_dir=f\"data/23-05-11-ml-data-CUTOFF8/{xanes_dir}\"\n",
    "    )\n",
    "    root = Path(f\"data/23-12-06_torch_models/cutoff8/{element_dir}\")\n",
    "    _torch_models_from_Crescendo(root, ensemble)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc628c-7187-4dfb-b718-d660b40a7ac1",
   "metadata": {},
   "source": [
    "# Find the best model for some other cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb78be7-a1e8-4a23-9ce3-eeb5dcd337bc",
   "metadata": {},
   "source": [
    "Note sometimes this causes the kernel to crash. Probably loading too much data at once. Hence why we're just saving everything as `torch` models and whatnot. Makes things way easier for everyone including me!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91672875-791d-485a-8103-8b119af3424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-modal models\n",
    "# data_dir = \"data/23-04-26-ml-data/C-XANES_N-XANES_O-XANES\"\n",
    "# models_path_root = \"data/23-05-03-hp\"\n",
    "# model_signatures = [\"C-N-O_only_C\", \"C-N-O_only_N\", \"C-N-O_only_O\", \"C-N-O\"]\n",
    "\n",
    "# X-only model\n",
    "ELEMENT = \"O\"\n",
    "data_dir = f\"data/23-04-26-ml-data/{ELEMENT}-XANES\"\n",
    "models_path_root = \"data/23-05-03-hp\"\n",
    "model_signatures = [f\"{ELEMENT}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4967e8d-e65b-456c-8b9a-ce58fcd6c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sig in model_signatures:\n",
    "\n",
    "    hp_model_path = Path(models_path_root) / sig\n",
    "    hptuned_set = CrescendoHPTunedSet.from_root(hp_model_path, data_dir=data_dir)\n",
    "    best_estimator = hptuned_set.get_best_estimator(hptuned_set.X_val, hptuned_set.Y_val)[0]\n",
    "\n",
    "    target_path = Path(\"data/23-12-06_torch_models/solo_estimators\") / sig\n",
    "    target_path.mkdir(exist_ok=True, parents=True)\n",
    "    d_scaler, _ = scaler_from_estimator(best_estimator)\n",
    "    model = best_estimator.get_model()\n",
    "\n",
    "    save_json(d_scaler, target_path / \"scaler.json\")\n",
    "    torch.save(model, target_path / \"model.pt\")\n",
    "\n",
    "    del hptuned_set\n",
    "    del best_estimator\n",
    "    del model\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd03d9e-6762-420f-9477-a454315c8aaa",
   "metadata": {},
   "source": [
    "Do the same thing for the cutoff-8 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5293d0e1-6355-4348-963b-abd2d4fe3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-modal models\n",
    "# data_dir = \"data/23-05-11-ml-data-CUTOFF8/C-XANES_N-XANES_O-XANES\"\n",
    "# models_path_root = \"data/23-05-13-hp-CUTOFF8\"\n",
    "# model_signatures = [\"C-N-O_only_C\", \"C-N-O_only_N\", \"C-N-O_only_O\", \"C-N-O\"]\n",
    "\n",
    "# X-only model\n",
    "ELEMENT = \"O\"\n",
    "data_dir = f\"data/23-05-11-ml-data-CUTOFF8/{ELEMENT}-XANES\"\n",
    "models_path_root = \"data/23-05-13-hp-CUTOFF8\"\n",
    "model_signatures = [f\"{ELEMENT}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0c4bf-b9bd-4968-a59a-55c625ff17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sig in model_signatures:\n",
    "\n",
    "    hp_model_path = Path(models_path_root) / sig\n",
    "    hptuned_set = CrescendoHPTunedSet.from_root(hp_model_path, data_dir=data_dir)\n",
    "    best_estimator = hptuned_set.get_best_estimator(hptuned_set.X_val, hptuned_set.Y_val)[0]\n",
    "\n",
    "    target_path = Path(\"data/23-12-06_torch_models/solo_estimators_cutoff8\") / sig\n",
    "    target_path.mkdir(exist_ok=True, parents=True)\n",
    "    d_scaler, _ = scaler_from_estimator(best_estimator)\n",
    "    model = best_estimator.get_model()\n",
    "\n",
    "    save_json(d_scaler, target_path / \"scaler.json\")\n",
    "    torch.save(model, target_path / \"model.pt\")\n",
    "\n",
    "    del hptuned_set\n",
    "    del best_estimator\n",
    "    del model\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5654cf-1214-4f90-b1c8-da649f77fcf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
